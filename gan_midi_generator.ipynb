{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "music_GAN_new_1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "oexgac33krit",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Generative Adversarial Networkによるメロディ生成"
      ]
    },
    {
      "metadata": {
        "id": "PCnkDbKPk4O9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Google Colab用環境設定"
      ]
    },
    {
      "metadata": {
        "id": "B8geE1sxXtB2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o1nLrsCnXtvq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install music21"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RzNkjwj-qN2y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## プログラム"
      ]
    },
    {
      "metadata": {
        "id": "lxqPQdCWqRID",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 初期設定"
      ]
    },
    {
      "metadata": {
        "id": "SYBIARHbqZwU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import csv\n",
        "from music21 import converter, instrument, note, chord, stream\n",
        "from keras.layers import Input\n",
        "from keras.layers import RepeatVector, Dense, TimeDistributed\n",
        "from keras.layers import LSTM, CuDNNLSTM \n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Model\n",
        "from keras.optimizers import RMSprop"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A2UaWUg9XqLH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max_length = 100\n",
        "latent_dim = 32\n",
        "lstm_dim = 512\n",
        "steps = 15001\n",
        "batch_size = 128\n",
        "\n",
        "midi_dir =  '/content/gdrive/My Drive/Colab/midi_songs'\n",
        "out_dir = '/content/gdrive/My Drive/Colab/gan_output'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J3Xpv7caq4Gz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### MIDIファイルの読み込みと前処理"
      ]
    },
    {
      "metadata": {
        "id": "QjY3J8ErXqLL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def parse_midi_files(dir):\n",
        "    notes = []\n",
        "    songs = []\n",
        "    file_list = []\n",
        "    \n",
        "    files = glob.glob(os.path.join(dir, '*.mid'))\n",
        "\n",
        "    for file in files:\n",
        "        song = []\n",
        "        \n",
        "        file_list.append(os.path.basename(file))\n",
        "        midi = converter.parse(file)\n",
        "\n",
        "        print(\"Parsing %s\" % file)\n",
        "\n",
        "        notes_to_parse = None\n",
        "\n",
        "        try: # file has instrument parts\n",
        "            s2 = instrument.partitionByInstrument(midi)\n",
        "            notes_to_parse = s2.parts[0].recurse() \n",
        "        except: # file has notes in a flat structure\n",
        "            notes_to_parse = midi.flat.notes\n",
        "\n",
        "        for element in notes_to_parse:\n",
        "            if isinstance(element, note.Note):\n",
        "                song.append(str(element.pitch))\n",
        "            elif isinstance(element, chord.Chord):\n",
        "                song.append('.'.join(str(n) for n in element.normalOrder))\n",
        "        songs.append(song)\n",
        "        notes += song\n",
        "\n",
        "    return notes, songs, file_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yyDm8fJlXqLO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "24e19b10-b3ba-4d58-dd5d-b02ccd1ead48"
      },
      "cell_type": "code",
      "source": [
        "notes, songs, file_list = parse_midi_files(midi_dir)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parsing /content/gdrive/My Drive/Colab/midi_songs/bwv786.mid\n",
            "Parsing /content/gdrive/My Drive/Colab/midi_songs/bwv785.mid\n",
            "Parsing /content/gdrive/My Drive/Colab/midi_songs/bwv784.mid\n",
            "Parsing /content/gdrive/My Drive/Colab/midi_songs/bwv783.mid\n",
            "Parsing /content/gdrive/My Drive/Colab/midi_songs/bwv782.mid\n",
            "Parsing /content/gdrive/My Drive/Colab/midi_songs/bwv781.mid\n",
            "Parsing /content/gdrive/My Drive/Colab/midi_songs/bwv780.mid\n",
            "Parsing /content/gdrive/My Drive/Colab/midi_songs/bwv779.mid\n",
            "Parsing /content/gdrive/My Drive/Colab/midi_songs/bwv778.mid\n",
            "Parsing /content/gdrive/My Drive/Colab/midi_songs/bwv777.mid\n",
            "Parsing /content/gdrive/My Drive/Colab/midi_songs/bwv776.mid\n",
            "Parsing /content/gdrive/My Drive/Colab/midi_songs/bwv775.mid\n",
            "Parsing /content/gdrive/My Drive/Colab/midi_songs/bwv774.mid\n",
            "Parsing /content/gdrive/My Drive/Colab/midi_songs/bwv773.mid\n",
            "Parsing /content/gdrive/My Drive/Colab/midi_songs/bwv772.mid\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "f65klMUxXqLT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pitchnames = sorted(set(item for item in notes))\n",
        "n_vocab = len(pitchnames)\n",
        "\n",
        "note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
        "int_to_note = dict([[number, note] for note, number in note_to_int.items()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C5mhZUtIXqLY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def prepare_sequences(notes, sequence_length=100):\n",
        "    # get all pitch names\n",
        "    pitchnames = sorted(set(item for item in notes))\n",
        "    n_vocab = len(pitchnames)\n",
        "    \n",
        "    # convert notes to one-hot encoded\n",
        "    one_hot_notes = []\n",
        "    for note in notes:\n",
        "        one_hot_note = np.zeros(n_vocab)\n",
        "        one_hot_note[note_to_int[note]] = 1\n",
        "        one_hot_notes.append(one_hot_note)\n",
        "\n",
        "    network_input = []\n",
        "    network_output = []\n",
        "\n",
        "    # create input sequences and the corresponding outputs\n",
        "    for i in range(0, len(one_hot_notes) - sequence_length, 1):\n",
        "        sequence_in = one_hot_notes[i:i + sequence_length]\n",
        "        sequence_out = one_hot_notes[i + sequence_length]\n",
        "        network_input.append(sequence_in)\n",
        "        network_output.append(sequence_out)\n",
        "\n",
        "    n_patterns = len(network_input)\n",
        "\n",
        "    # reshape the input into a format compatible with LSTM layers\n",
        "    network_input = np.reshape(network_input, (n_patterns, sequence_length, n_vocab))\n",
        "\n",
        "    network_output = np.array(network_output)\n",
        "\n",
        "    return (network_input, network_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TGlVUsltXqLb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "network_input, network_output = prepare_sequences(notes, sequence_length=max_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p3nCa1L6q_5b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### モデルの定義"
      ]
    },
    {
      "metadata": {
        "id": "bF88UInqrGqi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "モデル定義用関数"
      ]
    },
    {
      "metadata": {
        "id": "J6wGUHdOXqLg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Generator(latent_dim=32, max_length=100, lstm_dim=512, n_vocab=None):\n",
        "    model_input = Input(shape=(max_length, latent_dim,))\n",
        "    x = CuDNNLSTM(lstm_dim, return_sequences=True)(model_input)\n",
        "    model_output = TimeDistributed(Dense(n_vocab, activation='softmax'))(x)\n",
        "    model = Model(model_input, model_output)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1_EKThp_XqLj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Discriminator(max_length=100, n_vocab=None, lstm_dim=512, opt=Adam(lr=1e-4)):\n",
        "    model_input = Input(shape=(max_length, n_vocab))\n",
        "    x = CuDNNLSTM(lstm_dim)(model_input)\n",
        "    model_output = Dense(2, activation='softmax')(x)\n",
        "    model = Model(model_input, model_output)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CTYMG1RiXqLn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def combined_network(generator, discriminator, max_length=100, latent_dim=32, opt=Adam(lr=1e-3)):\n",
        "    gan_input = Input(shape=(max_length, latent_dim))\n",
        "    x = generator(gan_input)\n",
        "    gan_output = discriminator(x)\n",
        "    model = Model(gan_input, gan_output)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nz5XWf4KXqLr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_trainable(net, val):\n",
        "    net.trainable = val\n",
        "    for l in net.layers:\n",
        "        l.trainable = val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pajbP91nrJS9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "途中でメロディサンプルを出力するための関数"
      ]
    },
    {
      "metadata": {
        "id": "y0LFIygXXqLt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_midi(prediction_output, file_path):\n",
        "    \"\"\" convert the output from the prediction to notes and create a midi file\n",
        "        from the notes \"\"\"\n",
        "    offset = 0\n",
        "    output_notes = []\n",
        "\n",
        "    # create note and chord objects based on the values generated by the model\n",
        "    for pattern in prediction_output:\n",
        "        # pattern is a chord\n",
        "        if ('.' in pattern) or pattern.isdigit():\n",
        "            notes_in_chord = pattern.split('.')\n",
        "            notes = []\n",
        "            for current_note in notes_in_chord:\n",
        "                new_note = note.Note(int(current_note))\n",
        "                new_note.storedInstrument = instrument.Piano()\n",
        "                notes.append(new_note)\n",
        "            new_chord = chord.Chord(notes)\n",
        "            new_chord.offset = offset\n",
        "            output_notes.append(new_chord)\n",
        "        # pattern is a note\n",
        "        else:\n",
        "            new_note = note.Note(pattern)\n",
        "            new_note.offset = offset\n",
        "            new_note.storedInstrument = instrument.Piano()\n",
        "            output_notes.append(new_note)\n",
        "\n",
        "        # increase offset each iteration so that notes do not stack\n",
        "        offset += 0.5\n",
        "\n",
        "    midi_stream = stream.Stream(output_notes)\n",
        "    midi_stream.write('midi', fp=file_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cL1ZuEwSrP-k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "モデルの構築"
      ]
    },
    {
      "metadata": {
        "id": "KEyD2_ggXqLx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "de614751-0993-4a60-8487-0413f4dd3e9b"
      },
      "cell_type": "code",
      "source": [
        "generator = Generator(latent_dim=latent_dim, max_length=max_length, \n",
        "                                        lstm_dim=lstm_dim, n_vocab=n_vocab)\n",
        "discriminator = Discriminator(max_length=max_length, n_vocab=n_vocab, \n",
        "                                                    lstm_dim=lstm_dim, opt=RMSprop(lr=8e-4, clipvalue=1.0))\n",
        "make_trainable(discriminator, False)\n",
        "GAN = combined_network(generator, discriminator, latent_dim=32, \n",
        "                                                opt=RMSprop(lr=4e-4, clipvalue=1.0))\n",
        "GAN.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         (None, 100, 32)           0         \n",
            "_________________________________________________________________\n",
            "model_4 (Model)              (None, 100, 124)          1181820   \n",
            "_________________________________________________________________\n",
            "model_5 (Model)              (None, 2)                 1307650   \n",
            "=================================================================\n",
            "Total params: 2,489,470\n",
            "Trainable params: 1,181,820\n",
            "Non-trainable params: 1,307,650\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MYWR6KMmrSjY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 訓練の実行"
      ]
    },
    {
      "metadata": {
        "id": "H5iusdiUXqL0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5090
        },
        "outputId": "1f29c4ae-bc84-4222-d0f8-8eef5e4a62f5"
      },
      "cell_type": "code",
      "source": [
        "f = open(os.path.join(out_dir, 'gan_log.csv'),'a')\n",
        "writer = csv.writer(f)\n",
        "\n",
        "for step in range(steps):  \n",
        "    input_batch = network_input[np.random.randint(0, network_input.shape[0], size=batch_size),:,:]    \n",
        "    noise_gen = np.random.uniform(0,1,size=[batch_size, max_length, latent_dim])\n",
        "    generated_melodies = generator.predict(noise_gen)\n",
        "\n",
        "    make_trainable(discriminator,True)\n",
        "\n",
        "    X = np.concatenate((input_batch, generated_melodies))\n",
        "    y = np.zeros([2 * batch_size, 2])\n",
        "    y[:batch_size,1] = 1\n",
        "    y[batch_size:,0] = 1\n",
        "\n",
        "    d_loss = discriminator.train_on_batch(X,y)\n",
        "\n",
        "    make_trainable(discriminator,False)\n",
        "\n",
        "    noise_gen = np.random.uniform(0,1,size=[batch_size, max_length, latent_dim])\n",
        "    y2 = np.zeros([batch_size, 2])\n",
        "    y2[:,1] = 1\n",
        "\n",
        "    a_loss = GAN.train_on_batch(noise_gen, y2 )\n",
        "\n",
        "    writer.writerow([step, d_loss, a_loss])\n",
        "\n",
        "    if step % 100 == 0:\n",
        "        # Save model weights\n",
        "        GAN.save_weights(os.path.join(out_dir, 'gan_{}.h5'.format(step)))\n",
        "\n",
        "        # Print metrics\n",
        "        print('discriminator loss at step %s: %s' % (step, d_loss))\n",
        "        print('adversarial loss at step %s: %s' % (step, a_loss))\n",
        "\n",
        "        generated_indices = np.argmax(generated_melodies, axis=2)\n",
        "\n",
        "        generated_song = [int_to_note[index] for index in generated_indices[0]]\n",
        "\n",
        "        # Save Generated Song Midi\n",
        "        create_midi(generated_song, os.path.join(out_dir, 'generated_song_' + str(step) + '.mid'))\n",
        "\n",
        "f.close()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "discriminator loss at step 0: 0.6945064\n",
            "adversarial loss at step 0: 0.7772623\n",
            "discriminator loss at step 100: 0.69562113\n",
            "adversarial loss at step 100: 0.78512895\n",
            "discriminator loss at step 200: 0.6815994\n",
            "adversarial loss at step 200: 0.72523034\n",
            "discriminator loss at step 300: 0.68020093\n",
            "adversarial loss at step 300: 0.5696613\n",
            "discriminator loss at step 400: 0.7038646\n",
            "adversarial loss at step 400: 0.5639577\n",
            "discriminator loss at step 500: 0.7339598\n",
            "adversarial loss at step 500: 0.6520477\n",
            "discriminator loss at step 600: 0.6827715\n",
            "adversarial loss at step 600: 0.7072907\n",
            "discriminator loss at step 700: 0.55002224\n",
            "adversarial loss at step 700: 2.3005075\n",
            "discriminator loss at step 800: 0.0006721217\n",
            "adversarial loss at step 800: 8.271555\n",
            "discriminator loss at step 900: 0.31230256\n",
            "adversarial loss at step 900: 1.6403515\n",
            "discriminator loss at step 1000: 0.6962252\n",
            "adversarial loss at step 1000: 1.0882454\n",
            "discriminator loss at step 1100: 0.6923334\n",
            "adversarial loss at step 1100: 0.8202803\n",
            "discriminator loss at step 1200: 0.71064115\n",
            "adversarial loss at step 1200: 1.0356175\n",
            "discriminator loss at step 1300: 0.6857885\n",
            "adversarial loss at step 1300: 0.68213296\n",
            "discriminator loss at step 1400: 0.7296697\n",
            "adversarial loss at step 1400: 1.0214105\n",
            "discriminator loss at step 1500: 0.5836533\n",
            "adversarial loss at step 1500: 0.7223532\n",
            "discriminator loss at step 1600: 0.66428715\n",
            "adversarial loss at step 1600: 1.0567905\n",
            "discriminator loss at step 1700: 0.025187498\n",
            "adversarial loss at step 1700: 5.183106\n",
            "discriminator loss at step 1800: 0.50803965\n",
            "adversarial loss at step 1800: 1.176491\n",
            "discriminator loss at step 1900: 0.43059313\n",
            "adversarial loss at step 1900: 0.21117392\n",
            "discriminator loss at step 2000: 0.77727884\n",
            "adversarial loss at step 2000: 0.686046\n",
            "discriminator loss at step 2100: 0.19945657\n",
            "adversarial loss at step 2100: 1.9778527\n",
            "discriminator loss at step 2200: 0.0284855\n",
            "adversarial loss at step 2200: 3.5188842\n",
            "discriminator loss at step 2300: 0.09639853\n",
            "adversarial loss at step 2300: 2.6940286\n",
            "discriminator loss at step 2400: 0.77945256\n",
            "adversarial loss at step 2400: 0.43865937\n",
            "discriminator loss at step 2500: 0.73843014\n",
            "adversarial loss at step 2500: 1.0761151\n",
            "discriminator loss at step 2600: 0.109223075\n",
            "adversarial loss at step 2600: 3.1929832\n",
            "discriminator loss at step 2700: 0.2075404\n",
            "adversarial loss at step 2700: 2.2179182\n",
            "discriminator loss at step 2800: 0.5920789\n",
            "adversarial loss at step 2800: 1.7456532\n",
            "discriminator loss at step 2900: 0.0021243307\n",
            "adversarial loss at step 2900: 5.862898\n",
            "discriminator loss at step 3000: 0.25746182\n",
            "adversarial loss at step 3000: 1.791025\n",
            "discriminator loss at step 3100: 0.26351726\n",
            "adversarial loss at step 3100: 1.8273116\n",
            "discriminator loss at step 3200: 0.0070435815\n",
            "adversarial loss at step 3200: 5.857937\n",
            "discriminator loss at step 3300: 0.06501551\n",
            "adversarial loss at step 3300: 3.3927476\n",
            "discriminator loss at step 3400: 0.0011091923\n",
            "adversarial loss at step 3400: 6.4348855\n",
            "discriminator loss at step 3500: 0.29829228\n",
            "adversarial loss at step 3500: 5.810976\n",
            "discriminator loss at step 3600: 0.009340356\n",
            "adversarial loss at step 3600: 4.861683\n",
            "discriminator loss at step 3700: 0.00013682776\n",
            "adversarial loss at step 3700: 8.795069\n",
            "discriminator loss at step 3800: 0.0217792\n",
            "adversarial loss at step 3800: 5.308923\n",
            "discriminator loss at step 3900: 0.0020881258\n",
            "adversarial loss at step 3900: 7.371516\n",
            "discriminator loss at step 4000: 0.042030115\n",
            "adversarial loss at step 4000: 1.8382871\n",
            "discriminator loss at step 4100: 0.67153966\n",
            "adversarial loss at step 4100: 0.5984286\n",
            "discriminator loss at step 4200: 0.05254406\n",
            "adversarial loss at step 4200: 4.239065\n",
            "discriminator loss at step 4300: 0.04313128\n",
            "adversarial loss at step 4300: 4.7206163\n",
            "discriminator loss at step 4400: 0.016330663\n",
            "adversarial loss at step 4400: 6.8963594\n",
            "discriminator loss at step 4500: 0.008409599\n",
            "adversarial loss at step 4500: 4.7212734\n",
            "discriminator loss at step 4600: 0.057682626\n",
            "adversarial loss at step 4600: 6.186781\n",
            "discriminator loss at step 4700: 0.0006632539\n",
            "adversarial loss at step 4700: 7.3609934\n",
            "discriminator loss at step 4800: 0.009948205\n",
            "adversarial loss at step 4800: 5.3010635\n",
            "discriminator loss at step 4900: 0.9759001\n",
            "adversarial loss at step 4900: 0.15200229\n",
            "discriminator loss at step 5000: 0.005656978\n",
            "adversarial loss at step 5000: 5.1856394\n",
            "discriminator loss at step 5100: 0.006417792\n",
            "adversarial loss at step 5100: 5.3007803\n",
            "discriminator loss at step 5200: 0.01563538\n",
            "adversarial loss at step 5200: 4.3349466\n",
            "discriminator loss at step 5300: 0.0019985272\n",
            "adversarial loss at step 5300: 5.999052\n",
            "discriminator loss at step 5400: 0.00018340716\n",
            "adversarial loss at step 5400: 8.330317\n",
            "discriminator loss at step 5500: 4.552032e-05\n",
            "adversarial loss at step 5500: 9.733013\n",
            "discriminator loss at step 5600: 0.0005428351\n",
            "adversarial loss at step 5600: 7.356851\n",
            "discriminator loss at step 5700: 0.11755385\n",
            "adversarial loss at step 5700: 2.563147\n",
            "discriminator loss at step 5800: 0.29574904\n",
            "adversarial loss at step 5800: 1.6034458\n",
            "discriminator loss at step 5900: 0.3595086\n",
            "adversarial loss at step 5900: 0.11039574\n",
            "discriminator loss at step 6000: 0.7145996\n",
            "adversarial loss at step 6000: 1.0351412\n",
            "discriminator loss at step 6100: 0.44602007\n",
            "adversarial loss at step 6100: 2.357567\n",
            "discriminator loss at step 6200: 0.08649709\n",
            "adversarial loss at step 6200: 3.6826203\n",
            "discriminator loss at step 6300: 0.087258205\n",
            "adversarial loss at step 6300: 4.353159\n",
            "discriminator loss at step 6400: 0.6923733\n",
            "adversarial loss at step 6400: 0.6025084\n",
            "discriminator loss at step 6500: 0.7504846\n",
            "adversarial loss at step 6500: 0.33044308\n",
            "discriminator loss at step 6600: 0.68810534\n",
            "adversarial loss at step 6600: 0.67024606\n",
            "discriminator loss at step 6700: 0.6665529\n",
            "adversarial loss at step 6700: 0.51044095\n",
            "discriminator loss at step 6800: 0.2976712\n",
            "adversarial loss at step 6800: 2.825978\n",
            "discriminator loss at step 6900: 0.0680767\n",
            "adversarial loss at step 6900: 4.6806498\n",
            "discriminator loss at step 7000: 0.0860714\n",
            "adversarial loss at step 7000: 3.6089582\n",
            "discriminator loss at step 7100: 0.07209104\n",
            "adversarial loss at step 7100: 2.9901426\n",
            "discriminator loss at step 7200: 0.059113353\n",
            "adversarial loss at step 7200: 3.9087603\n",
            "discriminator loss at step 7300: 0.036807526\n",
            "adversarial loss at step 7300: 4.2243366\n",
            "discriminator loss at step 7400: 0.05208068\n",
            "adversarial loss at step 7400: 5.1597786\n",
            "discriminator loss at step 7500: 0.00020372568\n",
            "adversarial loss at step 7500: 8.032946\n",
            "discriminator loss at step 7600: 0.015256517\n",
            "adversarial loss at step 7600: 4.505352\n",
            "discriminator loss at step 7700: 0.13611013\n",
            "adversarial loss at step 7700: 6.795527\n",
            "discriminator loss at step 7800: 0.080333546\n",
            "adversarial loss at step 7800: 3.067197\n",
            "discriminator loss at step 7900: 0.0018671919\n",
            "adversarial loss at step 7900: 6.6611447\n",
            "discriminator loss at step 8000: 0.0017376584\n",
            "adversarial loss at step 8000: 6.5792103\n",
            "discriminator loss at step 8100: 0.08566986\n",
            "adversarial loss at step 8100: 3.3165975\n",
            "discriminator loss at step 8200: 0.07062807\n",
            "adversarial loss at step 8200: 3.6463933\n",
            "discriminator loss at step 8300: 0.069794856\n",
            "adversarial loss at step 8300: 5.0000887\n",
            "discriminator loss at step 8400: 0.018662082\n",
            "adversarial loss at step 8400: 4.8502216\n",
            "discriminator loss at step 8500: 0.095702305\n",
            "adversarial loss at step 8500: 4.1842813\n",
            "discriminator loss at step 8600: 0.07908\n",
            "adversarial loss at step 8600: 3.5866275\n",
            "discriminator loss at step 8700: 0.24489097\n",
            "adversarial loss at step 8700: 3.198555\n",
            "discriminator loss at step 8800: 1.1687614\n",
            "adversarial loss at step 8800: 4.593707\n",
            "discriminator loss at step 8900: 0.2512832\n",
            "adversarial loss at step 8900: 1.3752861\n",
            "discriminator loss at step 9000: 0.91955805\n",
            "adversarial loss at step 9000: 2.1169474\n",
            "discriminator loss at step 9100: 0.4815237\n",
            "adversarial loss at step 9100: 1.8488907\n",
            "discriminator loss at step 9200: 0.1233809\n",
            "adversarial loss at step 9200: 4.13219\n",
            "discriminator loss at step 9300: 0.28095067\n",
            "adversarial loss at step 9300: 2.2093763\n",
            "discriminator loss at step 9400: 0.07110616\n",
            "adversarial loss at step 9400: 3.60655\n",
            "discriminator loss at step 9500: 0.046153765\n",
            "adversarial loss at step 9500: 4.056899\n",
            "discriminator loss at step 9600: 0.41633952\n",
            "adversarial loss at step 9600: 2.0318422\n",
            "discriminator loss at step 9700: 0.02942308\n",
            "adversarial loss at step 9700: 4.4898405\n",
            "discriminator loss at step 9800: 0.06177688\n",
            "adversarial loss at step 9800: 3.2014723\n",
            "discriminator loss at step 9900: 0.055246267\n",
            "adversarial loss at step 9900: 3.1631362\n",
            "discriminator loss at step 10000: 0.056918833\n",
            "adversarial loss at step 10000: 3.7471604\n",
            "discriminator loss at step 10100: 5.525427\n",
            "adversarial loss at step 10100: 4.921899\n",
            "discriminator loss at step 10200: 0.010414368\n",
            "adversarial loss at step 10200: 5.193142\n",
            "discriminator loss at step 10300: 0.083174095\n",
            "adversarial loss at step 10300: 3.0684845\n",
            "discriminator loss at step 10400: 0.07977247\n",
            "adversarial loss at step 10400: 4.2367926\n",
            "discriminator loss at step 10500: 0.044609077\n",
            "adversarial loss at step 10500: 3.6170018\n",
            "discriminator loss at step 10600: 0.06527938\n",
            "adversarial loss at step 10600: 4.8713684\n",
            "discriminator loss at step 10700: 0.07149866\n",
            "adversarial loss at step 10700: 3.2225082\n",
            "discriminator loss at step 10800: 0.19708402\n",
            "adversarial loss at step 10800: 2.236671\n",
            "discriminator loss at step 10900: 0.120315656\n",
            "adversarial loss at step 10900: 2.776815\n",
            "discriminator loss at step 11000: 0.13850729\n",
            "adversarial loss at step 11000: 2.977813\n",
            "discriminator loss at step 11100: 0.034828648\n",
            "adversarial loss at step 11100: 4.42464\n",
            "discriminator loss at step 11200: 0.06081961\n",
            "adversarial loss at step 11200: 3.7948174\n",
            "discriminator loss at step 11300: 0.001957829\n",
            "adversarial loss at step 11300: 6.243638\n",
            "discriminator loss at step 11400: 0.039727993\n",
            "adversarial loss at step 11400: 4.1054974\n",
            "discriminator loss at step 11500: 0.031826943\n",
            "adversarial loss at step 11500: 3.7714527\n",
            "discriminator loss at step 11600: 0.260619\n",
            "adversarial loss at step 11600: 1.994474\n",
            "discriminator loss at step 11700: 0.13838449\n",
            "adversarial loss at step 11700: 4.662038\n",
            "discriminator loss at step 11800: 0.043924544\n",
            "adversarial loss at step 11800: 3.724414\n",
            "discriminator loss at step 11900: 0.017065704\n",
            "adversarial loss at step 11900: 5.442362\n",
            "discriminator loss at step 12000: 0.0008281379\n",
            "adversarial loss at step 12000: 7.088082\n",
            "discriminator loss at step 12100: 0.0044949385\n",
            "adversarial loss at step 12100: 7.0181856\n",
            "discriminator loss at step 12200: 0.019787224\n",
            "adversarial loss at step 12200: 4.0054984\n",
            "discriminator loss at step 12300: 0.104043946\n",
            "adversarial loss at step 12300: 2.8865867\n",
            "discriminator loss at step 12400: 0.11140588\n",
            "adversarial loss at step 12400: 4.714983\n",
            "discriminator loss at step 12500: 0.11671102\n",
            "adversarial loss at step 12500: 2.6056213\n",
            "discriminator loss at step 12600: 0.06533911\n",
            "adversarial loss at step 12600: 3.0904741\n",
            "discriminator loss at step 12700: 0.080121644\n",
            "adversarial loss at step 12700: 3.8338127\n",
            "discriminator loss at step 12800: 0.12346983\n",
            "adversarial loss at step 12800: 2.9642122\n",
            "discriminator loss at step 12900: 0.20552395\n",
            "adversarial loss at step 12900: 4.014247\n",
            "discriminator loss at step 13000: 0.059459317\n",
            "adversarial loss at step 13000: 1.4108615\n",
            "discriminator loss at step 13100: 0.23402584\n",
            "adversarial loss at step 13100: 3.476311\n",
            "discriminator loss at step 13200: 0.14208487\n",
            "adversarial loss at step 13200: 3.0240026\n",
            "discriminator loss at step 13300: 0.011204251\n",
            "adversarial loss at step 13300: 4.624278\n",
            "discriminator loss at step 13400: 0.034976825\n",
            "adversarial loss at step 13400: 4.1650305\n",
            "discriminator loss at step 13500: 0.010633382\n",
            "adversarial loss at step 13500: 5.3282175\n",
            "discriminator loss at step 13600: 0.047652453\n",
            "adversarial loss at step 13600: 4.310851\n",
            "discriminator loss at step 13700: 0.022474146\n",
            "adversarial loss at step 13700: 3.8245833\n",
            "discriminator loss at step 13800: 0.033841107\n",
            "adversarial loss at step 13800: 3.7043674\n",
            "discriminator loss at step 13900: 0.04187454\n",
            "adversarial loss at step 13900: 6.571056\n",
            "discriminator loss at step 14000: 0.0030792153\n",
            "adversarial loss at step 14000: 7.272068\n",
            "discriminator loss at step 14100: 0.0012355426\n",
            "adversarial loss at step 14100: 6.255667\n",
            "discriminator loss at step 14200: 0.031584613\n",
            "adversarial loss at step 14200: 4.155304\n",
            "discriminator loss at step 14300: 0.0047437754\n",
            "adversarial loss at step 14300: 5.6102085\n",
            "discriminator loss at step 14400: 2.468052\n",
            "adversarial loss at step 14400: 2.7710438\n",
            "discriminator loss at step 14500: 0.041622818\n",
            "adversarial loss at step 14500: 7.142991\n",
            "discriminator loss at step 14600: 0.035821196\n",
            "adversarial loss at step 14600: 4.273588\n",
            "discriminator loss at step 14700: 0.041953303\n",
            "adversarial loss at step 14700: 5.1047664\n",
            "discriminator loss at step 14800: 0.0032211854\n",
            "adversarial loss at step 14800: 7.7221193\n",
            "discriminator loss at step 14900: 0.0011213806\n",
            "adversarial loss at step 14900: 6.654162\n",
            "discriminator loss at step 15000: 0.0016118136\n",
            "adversarial loss at step 15000: 6.078462\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}